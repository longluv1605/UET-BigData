{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em1PHKaIde9i"
      },
      "source": [
        "# Setting up PySpark in Colab\n",
        "Spark is written in the Scala programming language and requires the Java Virtual Machine (JVM) to run. Therefore, our first task is to download Java.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8iQmSRXMdbHi"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rEpRqzQd5YD"
      },
      "source": [
        "Next, we will install Apache Spark 3.0.1 with Hadoop 2.7 from here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hnXK9lSdrcK",
        "outputId": "c27cc0b1-2d19-4b3b-9f05-8a5270d5a054"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-10-13 13:36:55--  https://dlcdn.apache.org/spark/spark-3.5.3/spark-3.5.3-bin-hadoop3.tgz\n",
            "Resolving dlcdn.apache.org (dlcdn.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
            "Connecting to dlcdn.apache.org (dlcdn.apache.org)|151.101.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 400864419 (382M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.5.3-bin-hadoop3.tgz’\n",
            "\n",
            "spark-3.5.3-bin-had 100%[===================>] 382.29M   183MB/s    in 2.1s    \n",
            "\n",
            "2024-10-13 13:36:57 (183 MB/s) - ‘spark-3.5.3-bin-hadoop3.tgz’ saved [400864419/400864419]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://dlcdn.apache.org/spark/spark-3.5.3/spark-3.5.3-bin-hadoop3.tgz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byFymcHMdxrE"
      },
      "source": [
        "Now, we just need to unzip that folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8Pf_fF21eGvo"
      },
      "outputs": [],
      "source": [
        "!tar xf spark-3.5.3-bin-hadoop3.tgz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCHitttefmIi"
      },
      "source": [
        "There is one last thing that we need to install and that is the findspark library. It will locate Spark on the system and import it as a regular library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yX8hTPEUeHTk"
      },
      "outputs": [],
      "source": [
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CivfcBffx2r"
      },
      "source": [
        "Now that we have installed all the necessary dependencies in Colab, it is time to set the environment path. This will enable us to run Pyspark in the Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s24UYNmX-JWA",
        "outputId": "c97e603f-bd66-46c7-ca76-f34f5dd6541d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bin   data\tjars\t    LICENSE   NOTICE  R\t\t RELEASE  yarn\n",
            "conf  examples\tkubernetes  licenses  python  README.md  sbin\n"
          ]
        }
      ],
      "source": [
        "!ls /content/spark-3.5.3-bin-hadoop3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qkhkgiTbfgCo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.3-bin-hadoop3\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdpWD3tXf3D1"
      },
      "source": [
        "Time for the real test!\n",
        "\n",
        "We need to locate Spark in the system. For that, we import findspark and use the findspark.init() method.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Dx8JrH5Ff0fH"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JF_kVi6gM2C"
      },
      "source": [
        "Bonus – If you want to know the location where Spark is installed, use findspark.find()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "FIs8OBMof5fW",
        "outputId": "95c8a4b4-da56-4e98-e0df-614b595aef27"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/spark-3.5.3-bin-hadoop3'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "findspark.find()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwaI8Iwpgg9p"
      },
      "source": [
        "Now, we can import SparkSession from pyspark.sql and create a SparkSession, which is the entry point to Spark.\n",
        "\n",
        "You can give a name to the session using appName() and add some configurations with config() if you wish.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DLQvsgE6gO6f"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcQegmIegnHd"
      },
      "source": [
        "Finally, print the SparkSession variable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "oCPA5p-GgkEL",
        "outputId": "6a7cb503-ca86-4347-c4a7-25e59026ff53"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://79a54e3d1be0:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Colab</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7d38b1785a50>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f2kxf_Xg3PW"
      },
      "source": [
        "If you want to view the Spark UI, you would have to include a few more lines of code to create a public URL for the UI page.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR8Wsn1-gtsf",
        "outputId": "2a941961-3f66-48d0-c8dd-99422cccc373"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-10-13 13:37:23--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.237.133.81, 54.161.241.46, 18.205.222.128, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.237.133.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13921656 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.28M  71.1MB/s    in 0.2s    \n",
            "\n",
            "2024-10-13 13:37:23 (71.1 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13921656/13921656]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ]
        }
      ],
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "get_ipython().system_raw('./ngrok http 4050 &')\n",
        "!curl -s http://localhost:4040/api/tunnels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uujjzy9g6TU",
        "outputId": "c78ded0e-e8e7-4ef3-acbf-df17d654f122"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"tunnels\":[],\"uri\":\"/api/tunnels\"}\n"
          ]
        }
      ],
      "source": [
        "!curl -s http://localhost:4040/api/tunnels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ew1kJW5gOZGh"
      },
      "source": [
        "# I. Apache Spark examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjRPHaGhT31G"
      },
      "source": [
        "## I.1. Spark DF example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PrrZlKqhyRl",
        "outputId": "55086bb7-22f3-4ff2-cc76-9301df188c7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+---+\n",
            "|first_name|age|\n",
            "+----------+---+\n",
            "|       sue| 32|\n",
            "|        li|  3|\n",
            "|       bob| 75|\n",
            "|       heo| 13|\n",
            "+----------+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a Spark DF\n",
        "df = spark.createDataFrame (\n",
        "    [\n",
        "        (\"sue\", 32),\n",
        "        (\"li\", 3),\n",
        "        (\"bob\", 75),\n",
        "        (\"heo\", 13),\n",
        "    ],\n",
        "    [\"first_name\", \"age\"],\n",
        ")\n",
        "\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIIme3GrU1p5",
        "outputId": "3a34ca99-c65f-49bf-d6dd-6588e9c0e796"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+---+----------+\n",
            "|first_name|age|life_stage|\n",
            "+----------+---+----------+\n",
            "|       sue| 32|     adult|\n",
            "|        li|  3|     child|\n",
            "|       bob| 75|     adult|\n",
            "|       heo| 13|  teenager|\n",
            "+----------+---+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Add a column to a Spark DF\n",
        "from pyspark.sql.functions import col, when\n",
        "\n",
        "df1 = df.withColumn(\n",
        "    \"life_stage\",\n",
        "    when(col(\"age\") < 13, \"child\")\n",
        "    .when(col(\"age\").between(13, 19), \"teenager\")\n",
        "    .otherwise(\"adult\"),\n",
        ")\n",
        "\n",
        "df1.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO_sPqlkVR10",
        "outputId": "81d4e604-eba0-49bb-b99e-ec4f5712de1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+---+\n",
            "|first_name|age|\n",
            "+----------+---+\n",
            "|       sue| 32|\n",
            "|        li|  3|\n",
            "|       bob| 75|\n",
            "|       heo| 13|\n",
            "+----------+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# df is unchanged\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivWJ9W71VaqY",
        "outputId": "dcd460f8-e129-4f35-a69c-94e7d825b95e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+---+----------+\n",
            "|first_name|age|life_stage|\n",
            "+----------+---+----------+\n",
            "|       sue| 32|     adult|\n",
            "|       bob| 75|     adult|\n",
            "|       heo| 13|  teenager|\n",
            "+----------+---+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Filter a Spark DF\n",
        "df1.where(col (\"life_stage\").isin ([\"teenager\", \"adult\"])).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bvtl8n0IVjrq",
        "outputId": "4a797fc0-61f0-40eb-fb8b-28cbb68da898"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+\n",
            "|avg(age)|\n",
            "+--------+\n",
            "|   30.75|\n",
            "+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Group by aggregation on Spark DF\n",
        "from pyspark.sql.functions import avg\n",
        "\n",
        "df1.select(avg(\"age\")).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umGqAb-uVzff",
        "outputId": "17c6efa2-3e17-41f3-e90b-acb95bc5bb67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+--------+\n",
            "|life_stage|avg(age)|\n",
            "+----------+--------+\n",
            "|     adult|    53.5|\n",
            "|  teenager|    13.0|\n",
            "|     child|     3.0|\n",
            "+----------+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Group by aggregation on Spark DF (continue)\n",
        "\n",
        "df1.groupBy(\"life_stage\").agg(avg(\"age\")).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOvI2Bm1V2Q4",
        "outputId": "d3ebd7b8-3d63-402d-eed4-2bd698364392"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+\n",
            "|avg(age)|\n",
            "+--------+\n",
            "|   30.75|\n",
            "+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Query the DataFrame with SQL\n",
        "spark.sql(\"select avg (age) from {df1}\", df1=df1).show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgkK4JDYW5KM",
        "outputId": "3251576a-4373-47ac-fa5a-2a15857e7857"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+--------+\n",
            "|life_stage|avg(age)|\n",
            "+----------+--------+\n",
            "|     adult|    53.5|\n",
            "|  teenager|    13.0|\n",
            "|     child|     3.0|\n",
            "+----------+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"select life_stage, avg (age) from {df1} group by life_stage\", df1=df1).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhm2ziV5XJOy"
      },
      "source": [
        "## I.2. Spark SQL example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "0Ro0GOudXQ-f"
      },
      "outputs": [],
      "source": [
        "df1.write.saveAsTable(\"some_people\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSc-zGXPXVRh",
        "outputId": "71e041db-c6b5-47d3-b788-59f6369109ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+---+----------+\n",
            "|first_name|age|life_stage|\n",
            "+----------+---+----------+\n",
            "|       sue| 32|     adult|\n",
            "|        li|  3|     child|\n",
            "|       bob| 75|     adult|\n",
            "|       heo| 13|  teenager|\n",
            "+----------+---+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql('select * from some_people').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D5nKcfoXY_Z",
        "outputId": "e6765bed-0269-450a-f849-9146416db29d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+---+----------+\n",
            "|first_name|age|life_stage|\n",
            "+----------+---+----------+\n",
            "|       sue| 32|     adult|\n",
            "|        li|  3|     child|\n",
            "|       bob| 75|     adult|\n",
            "|       heo| 13|  teenager|\n",
            "|     frank|  4|     child|\n",
            "+----------+---+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"INSERT INTO some_people VALUES ('frank', 4, 'child')\")\n",
        "spark.sql('select * from some_people').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckCEACuQX2eq",
        "outputId": "874818bc-e4f1-4189-b764-0a06933670bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+---+----------+\n",
            "|first_name|age|life_stage|\n",
            "+----------+---+----------+\n",
            "|       heo| 13|  teenager|\n",
            "+----------+---+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql('select * from some_people where life_stage=\"teenager\"').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfTQD5krX_3P"
      },
      "source": [
        "## I.3. Spark structured streaming example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "E5IDaYAlYFJi"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47FM6z0tYxS-"
      },
      "source": [
        "## I.4. Spark RDD example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "20KakcG2Y0qJ"
      },
      "outputs": [],
      "source": [
        "text_file = spark.sparkContext.textFile('data/some_text.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "TIDnXy4nZWq6"
      },
      "outputs": [],
      "source": [
        "counts = (text_file.flatMap(lambda line: line.split(\" \"))\n",
        "             .map(lambda word: (word, 1))\n",
        "             .reduceByKey(lambda a, b: a + b))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y70YR9kTZpEk",
        "outputId": "b56ee34e-9dcb-4088-86b5-4cb8f8ff8da0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('these', 2),\n",
              " ('are', 2),\n",
              " ('words', 3),\n",
              " ('more', 1),\n",
              " ('in', 1),\n",
              " ('english', 1)]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "counts.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYfKb04MZwYG"
      },
      "source": [
        "# II. Practice with Spark RDD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgB2I0aacXu_"
      },
      "source": [
        "## II.1. Create SparkContext object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "aPuvXzd9Z0fb"
      },
      "outputs": [],
      "source": [
        "# Spark Context object\n",
        "from pyspark import SparkConf, SparkContext\n",
        "\n",
        "sc = SparkContext.getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0TZtWkIcT4y"
      },
      "source": [
        "## II.2. Create a RDD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y72DYPVbcWt3",
        "outputId": "2950420c-eec6-4a5f-e8f5-7a535a5c2170"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ParallelCollectionRDD[64] at readRDDFromFile at PythonRDD.scala:289"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "iterator = [1, 2, 3, 4, 5]\n",
        "lines = sc.parallelize(iterator)\n",
        "lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7K10B81ck4m",
        "outputId": "5dffcd93-f769-4698-f165-79aa4806ada8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "some_text.txt MapPartitionsRDD[66] at textFile at NativeMethodAccessorImpl.java:0"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lines = sc.textFile(\"data/some_text.txt\")\n",
        "lines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js42ORVAc0dq"
      },
      "source": [
        "## II.3. RDD Transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkeY-JPecsCW",
        "outputId": "6a5baeeb-9537-45ff-d98a-e79cb9bd42cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[1], [1, 2], [1, 2, 3]]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# map(f)\n",
        "rdd = sc.parallelize([2, 3, 4])\n",
        "rdd.map(lambda x: list(range(1, x))).collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExZplDGcc72R",
        "outputId": "2fce90a9-a6e4-4993-ae80-3ab187a3bd6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 1, 2, 1, 2, 3, 1, 2, 3, 4]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# flatMap(f)\n",
        "rdd = sc.parallelize([2, 3, 4, 5])\n",
        "rdd.flatMap(lambda x: list(range(1, x))).collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gecqFA66dWx7",
        "outputId": "320fe191-25c0-485d-d8f3-87e946ba5471"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 2, 4, 6, 8]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# filter(f)\n",
        "rdd = sc.parallelize(range(10))\n",
        "rdd.filter(lambda x: x % 2 == 0).collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IkOa4-Wdqh9",
        "outputId": "d903295f-ffdc-454c-95c3-862325b74708"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 4, 2, 3]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# distinct()\n",
        "rdd = sc.parallelize([1, 1, 4, 2, 1, 3, 3])\n",
        "rdd.distinct().collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNJKzcT2d0aB",
        "outputId": "5d2248d1-d1c5-4703-bf8b-864bebccf6ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[4, 26, 39, 41, 42, 52, 63, 76, 80, 86, 97]"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# sample()\n",
        "rdd = sc.parallelize(range(100), 4)\n",
        "rdd.sample(False, 0.1, 81).collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQxIxzq6eagb",
        "outputId": "ada6ea9c-e686-42c9-ac6f-7d6827d1dbf9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 3, 4, 5, 6, 7, 8]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# union(otherRDD)\n",
        "rdd1 = sc.parallelize(range(5))\n",
        "rdd2 = sc.parallelize(range(3, 9))\n",
        "rdd3 = rdd1.union(rdd2)\n",
        "rdd3.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DnYBkz-fHKn",
        "outputId": "a1e07a62-4a08-45fb-e4d7-9bd14ca319e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[4, 3]"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# intersection(otherRDD)\n",
        "rdd1 = sc.parallelize(range(5))\n",
        "rdd2 = sc.parallelize(range(3, 9))\n",
        "rdd3 = rdd1.intersection(rdd2)\n",
        "rdd3.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HTCM41bfQFq",
        "outputId": "3ce5c0ad-03a4-4371-99e4-34a25fbe473c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 2, 1]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# subtract(otherRDD)\n",
        "rdd1 = sc.parallelize(range(5))\n",
        "rdd2 = sc.parallelize(range(3, 9))\n",
        "rdd3 = rdd1.subtract(rdd2)\n",
        "rdd3.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bz9qQXQ_fWLM",
        "outputId": "b9059c83-fab8-4e15-bcd3-9b57314626aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(1, 'a'), (1, 'b'), (2, 'a'), (2, 'b')]"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# cartesian(otherRDD)\n",
        "rdd1 = sc.parallelize([1, 2])\n",
        "rdd2 = sc.parallelize([\"a\", \"b\"])\n",
        "rdd1.cartesian(rdd2).collect()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foEc4JWufo43"
      },
      "source": [
        "## II.4. RDD Actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMf1M5YGfhkE",
        "outputId": "1dae0bf8-ba55-4e67-fce7-cbd176471aa8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 2, 3, 3]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get all value\n",
        "rdd = sc.parallelize([1, 2, 3, 3])\n",
        "rdd.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQtQz74GgAZQ",
        "outputId": "a48a517a-d65d-494a-c285-3d2ba68c0375"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Number of elements in the RDD\n",
        "rdd = sc.parallelize([1, 3, 1, 2, 2, 2])\n",
        "rdd.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSHWfodsgH70",
        "outputId": "6f3c7e3c-64a6-4e30-974e-7dcbd538bf75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "defaultdict(int, {1: 2, 3: 1, 2: 3})"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The count of each unique value in the RDD as a dictionary of {value: count} pairs.\n",
        "rdd.countByValue()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvSisaASgMiS",
        "outputId": "23ca5a18-f671-490f-e764-65e706f7ff8b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(1, 'b'), (2, 'd')]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get some values in an RDD\n",
        "rdd = sc.parallelize([(3, 'a'), (1, 'b'), (2, 'd')])\n",
        "rdd.takeOrdered(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hB_odZZDgU1b",
        "outputId": "56445b22-9431-46e5-e3c6-0e8422292381"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The reduce action\n",
        "rdd = sc.parallelize([1, 2, 3])\n",
        "rdd.reduce(lambda a, b: a + b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHGHZxcbg4Ct",
        "outputId": "f0a9d21f-3e2c-4a57-c3da-d80b0648d4dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdd.fold(0, lambda a, b: a + b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycWNNEsSg5oV",
        "outputId": "dd5d3115-ce39-47b6-8654-4d32d7f8d765"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14.5"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdd = sc.parallelize([1, 2, 4], 2) # RDD with 2 partitions\n",
        "\"\"\"\n",
        "RDD has 2 partition: say [1, 2] and [4]\n",
        "Sum in the partitions: 2.5 + (1 + 2) = 5.5 and 2.5 + (4) = 6.5\n",
        "Sum over partitions: 2.5 + (5.5 + 6.5) = 14.5\n",
        "\"\"\"\n",
        "rdd.fold(2.5, lambda a, b: a + b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbnrpXXjg9uD",
        "outputId": "bf3fa887-660a-4f5d-88ed-7c45cf94232d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdd = sc.parallelize([1, 2, 3], 5) # RDD with 5 partitions\n",
        "\"\"\"\n",
        "If number of P is more than number of elements\n",
        "=> Some P is empty\n",
        "-> [1][2][3][][]\n",
        "-> 2 + (2 + 1) + (2 + 2) + (2 + 3) + (2 + 0) + (2 + 0) = 18\n",
        "\"\"\"\n",
        "\n",
        "rdd.fold(2, lambda a, b: a + b)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XGxf-F_h1Zb",
        "outputId": "4cec0386-e544-489d-cfab-f6a236dd5379"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10, 4)"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seqOp = lambda acc, x: (acc[0] + x, acc[1] + 1)\n",
        "combOp = lambda acc1, acc2: (acc1[0] + acc2[0], acc1[1] + acc2[1])\n",
        "sc.parallelize([1, 2, 3, 4]).aggregate((0, 0), seqOp, combOp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SCOpXHapejl"
      },
      "source": [
        "acc = (0, 0) => (init sum, init count)\n",
        "--------------\n",
        "acc1 = (0, 0) | part1 = [1, 2]\n",
        "\n",
        "acc1 <> [1] --> (0 + 1, 0 + 1) = (1, 1)\n",
        "\n",
        "acc1 <> [2] --> (1 + 2, 1 + 1) = (3, 2)\n",
        "\n",
        "acc2 = (0, 0) | part2 = [3, 4]\n",
        "\n",
        "acc2 <> [3] --> (0 + 3, 0 + 1) = (3, 1)\n",
        "\n",
        "acc2 <> [4] --> (3 + 4, 1 + 1) = (7, 2)\n",
        "\n",
        "==> res = acc1 + acc2 = (3 + 7, 2 + 2) = (10, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "XSC5IgQepcUA"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC2eHRZYyELa"
      },
      "source": [
        "# III. Practice with Spark DF and SQL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3Plul7X6oRr"
      },
      "source": [
        "## III.1. Spark DF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "u45qvaAIyROr",
        "outputId": "bb0644e3-74dc-4bcb-f4f9-52db38530d53"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'John'"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark.sql import Row\n",
        "row1 = Row(name=\"John\", age=21)\n",
        "row2 = Row(name=\"James\", age=32)\n",
        "row3 = Row(name=\"Jane\", age=18)\n",
        "row1['name']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5w4pUDNX50gK",
        "outputId": "0fda0df1-f1f1-4d60-9fef-3b1ac6743c6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[name: string, age: bigint]"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = spark.createDataFrame([row1, row2, row3])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbAGHiFC51Xt",
        "outputId": "d01b5aa8-4216-43ad-d678-4b85d6957a05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+---+\n",
            "| name|age|\n",
            "+-----+---+\n",
            "| John| 21|\n",
            "|James| 32|\n",
            "| Jane| 18|\n",
            "+-----+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        " df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECvzk_yr54CA",
        "outputId": "0497fe8a-40f4-4ec7-f3dc-cc2f57b3c944"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- age: long (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nA5lzBD5-Ai",
        "outputId": "fbf0f018-3e21-4bee-c938-666443d55758"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " df.rdd.getNumPartitions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CS1CLCkA6AVg",
        "outputId": "44af830d-7fd1-4cf8-9075-83399a3d77f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+---+------+\n",
            "|  name|age|gender|\n",
            "+------+---+------+\n",
            "|  John| 21|  male|\n",
            "| James| 25|female|\n",
            "|Albert| 46|  male|\n",
            "+------+---+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rows = [\n",
        " Row(name=\"John\", age=21, gender=\"male\"),\n",
        " Row(name=\"James\", age=25, gender=\"female\"),\n",
        " Row(name=\"Albert\", age=46, gender=\"male\")\n",
        " ]\n",
        "df = spark.createDataFrame(rows)\n",
        "df.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDIlJEtZ6LL0",
        "outputId": "82371cc4-fb2c-4356-f66f-a92fb52d114b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+---+------+\n",
            "|  name|age|gender|\n",
            "+------+---+------+\n",
            "|  John| 21|  male|\n",
            "| James| 25|female|\n",
            "|Albert| 46|  male|\n",
            "+------+---+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "column_names = [\"name\", \"age\", \"gender\"]\n",
        "rows = [\n",
        " [\"John\", 21, \"male\"],\n",
        " [\"James\", 25, \"female\"],\n",
        " [\"Albert\", 46, \"male\"]\n",
        " ]\n",
        "df = spark.createDataFrame(rows, column_names)\n",
        "df.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urjimoM16OOM",
        "outputId": "1f5decb4-fe57-4338-81fd-76d3a009a7a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+---+------+\n",
            "|  name|age|gender|\n",
            "+------+---+------+\n",
            "|  John| 21|  male|\n",
            "| James| 25|female|\n",
            "|Albert| 46|  male|\n",
            "+------+---+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "column_names = [\"name\", \"age\", \"gender\"]\n",
        "rdd = sc.parallelize([\n",
        " (\"John\", 21, \"male\"),\n",
        " (\"James\", 25, \"female\"),\n",
        " (\"Albert\", 46, \"male\")\n",
        " ])\n",
        "df = spark.createDataFrame(rdd, column_names)\n",
        "df.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlrNhFjf6RZ-",
        "outputId": "a089a497-1a1f-4ec3-c061-a09bc6d973f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "StructType([StructField('name', StringType(), True), StructField('age', LongType(), True), StructField('gender', StringType(), True)])"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " df.schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbwiadVW6Tua",
        "outputId": "de97f01f-e284-43d5-ef38-c5b90ca9534f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            "\n",
            "+----+---+------+\n",
            "|name|age|gender|\n",
            "+----+---+------+\n",
            "|John| 21|  male|\n",
            "+----+---+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.types import *\n",
        "schema = StructType([\n",
        " StructField(\"name\", StringType(), True),\n",
        " StructField(\"age\", IntegerType(), True),\n",
        " StructField(\"gender\", StringType(), True)\n",
        " ])\n",
        "rows = [(\"John\", 21, \"male\")]\n",
        "df = spark.createDataFrame(rows, schema)\n",
        "df.printSchema()\n",
        "df.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3C9SJpAj6bT_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
